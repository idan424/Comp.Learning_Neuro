{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idan424/Comp.Learning_Neuro/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBqKegT4ZaD8"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.simplefilter(\"ignore\")\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw94aZpLBoOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7da9d2-3bc5-44d1-b1e3-c7b747edd5db"
      },
      "source": [
        "!git clone https://github.com/idan424/Comp.Learning_Neuro\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Comp.Learning_Neuro'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 9 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urvXfo7LHnCM",
        "outputId": "8a5773a1-8bfc-4c6a-9886-62a2f4cff1e7"
      },
      "source": [
        "PATH = '/content/Comp.Learning_Neuro/'\r\n",
        "_files = ['Run_200 02.trc', 'Run_300 02.trc', 'Run_400 02.trc', 'Run_500 02.trc']\r\n",
        "f = _files[0]\r\n",
        "\r\n",
        "def load_data(f):\r\n",
        "    _data = pd.read_table(PATH+f, header=4, index_col=0).iloc[:,:-1]\r\n",
        "    _data = _data.rename(columns={'Unnamed: 1':'Time'})\r\n",
        "    _data.reset_index(inplace=True)\r\n",
        "    labels = pd.DataFrame(np.ones(len(_data)-2)*int(f[4:7]))\r\n",
        "    return _data, labels\r\n",
        "\r\n",
        "def add_av(_data):\r\n",
        "    v_data = _data.copy().drop('Time', axis=1).diff()\r\n",
        "    a_data = v_data.diff()\r\n",
        "\r\n",
        "    v_data = v_data.rename(columns={n:f\"V_{n}\" for n in _data.columns})\r\n",
        "    a_data = a_data.rename(columns={n:f\"A_{n}\" for n in _data.columns})\r\n",
        "\r\n",
        "    return _data.join([v_data, a_data]).dropna()\r\n",
        "\r\n",
        "def divide_dataset(_data, label):\r\n",
        "    N = len(_data)//10\r\n",
        "    return [ _data.loc[10*n:10*(n+1)-1] for n in range(N)], label[0:N]\r\n",
        "\r\n",
        "def extract_features(seg_list):\r\n",
        "    data = pd.DataFrame([segment_processing(seg) for seg in seg_list]) \r\n",
        "    return data\r\n",
        "\r\n",
        "def segment_processing(_seg): #TODO: process a segment and concat results to the series\r\n",
        "    seg = _seg.drop('Time', axis=1)\r\n",
        "\r\n",
        "    mean_data = seg.mean().rename({n:f'mean_{n}'for n in seg.columns})\r\n",
        "    std_data = seg.std().rename({n:f'std_{n}'for n in seg.columns})\r\n",
        "\r\n",
        "    # פה צריך לחשוב על עוד פיצ'רים שאנחנו רוצים להכניס לשם\r\n",
        "\r\n",
        "    return mean_data.append(std_data)  # returns a pd.Series()\r\n",
        "\r\n",
        "\r\n",
        "def process_file(f):\r\n",
        "    X,y = load_data(f)\r\n",
        "    X = add_av(X)\r\n",
        "    segments, y = divide_dataset(X, y)\r\n",
        "    X = extract_features(segments)\r\n",
        "    return (X,y)  # returns a tuple\r\n",
        "\r\n",
        "\r\n",
        "files = _files\r\n",
        "Xy = [process_file(f) for f in files]\r\n",
        "Xy = list(zip(*Xy))  # this flip the tuple axis order\r\n",
        "\r\n",
        "X, y = pd.concat(Xy[0]), pd.concat(Xy[1])\r\n",
        "\r\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    mean_index      mean_X1      mean_Y1  ...  std_A_X42  std_A_Y42  std_A_Z42\n",
            "0         14.5  1082.295521  1095.245126  ...   0.071294   0.424134   0.215719\n",
            "1         23.5  1084.604082  1064.520578  ...   0.434725   0.788884   0.487597\n",
            "2         33.5  1070.161569  1020.873275  ...   0.689687   0.725455   0.701105\n",
            "3         43.5  1064.539822  1058.189897  ...   0.129670   0.510937   0.141166\n",
            "4         53.5  1071.028948  1100.267987  ...   0.045978   0.134596   0.128669\n",
            "..         ...          ...          ...  ...        ...        ...        ...\n",
            "34       361.5   993.593984  1049.887616  ...   0.466979   0.480481   0.376438\n",
            "35       371.5   973.351992  1018.116769  ...   0.413290   0.775528   0.726661\n",
            "36       381.5   969.060577  1000.450789  ...   0.633939   0.577788   0.538884\n",
            "37       391.5  1003.849861  1023.164068  ...   0.542608   0.228473   0.593324\n",
            "38       401.5  1008.346280   995.546229  ...   0.695254   1.166001   0.287491\n",
            "\n",
            "[190 rows x 762 columns]         0\n",
            "0   200.0\n",
            "1   200.0\n",
            "2   200.0\n",
            "3   200.0\n",
            "4   200.0\n",
            "..    ...\n",
            "34  500.0\n",
            "35  500.0\n",
            "36  500.0\n",
            "37  500.0\n",
            "38  500.0\n",
            "\n",
            "[190 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khAtRHyrF6sc"
      },
      "source": [
        "## ##########################################################"
      ]
    }
  ]
}